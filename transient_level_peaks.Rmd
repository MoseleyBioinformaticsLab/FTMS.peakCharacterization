---
title: "Transient Level Peak Picking"
author: "Robert M Flight"
date: "`r Sys.time()`"
commit: "`r substr(git2r::branch_target(git2r::head(git2r::repository())), 1, 8)`"
output: 
  pdf_document: 
    toc: yes
---

# Purpose

Working out how to do transient level peak picking.

# Data

Lets load up some data working at the transient level.

```{r load_transient_level}
library(notifier)

library(xcms)
library(dplyr)
library(ggplot2)
library(SIRM.FTMS.peakPickingMethods)
library(ggplot2)
options(digits = 16)
library(parallel)
```

So, our basic idea is to start very simply, and then escalate for peaks where the
simple things don't work. This requires us to set some simple metrics that tell
us whether or not a peak was likely picked correctly.

The steps I am imagining are:

* Classify as a flat or pointed peak
  * This is important because it changes how we handle looking at the center from
  the model.
* Fit a parabolic model to log-transformed values
* Flat peaks: check that center intensity is above max point, and between the flat points
* Pointed peaks: check that center intensity is within a weighted value of max, and near to it
* If checks fail, then:
* Try weighted parabolic fit, where weights are derived from point intensities
* Check again
* Try weighted **cauchy** fit
* Record generated parameters, and whether sanity checks pass for a peak.

## Peak Correspondence

We've got a bunch of methods for summarizing the peaks down to a single location
and intensity, now we need to figure out which one is best and most consistent.
To help with this, we need to match up the peaks across scans and get peak
correspondence. Lets play with that.

For peak correspondence, we need to set sensible limits for searching for a 
matching peak. To start, we will use a limit based on the digital resolution.

After an initial pass at matching peaks, we might use a calculation of the 
standard deviation of a window of m/z. To enable this, we take a middle m/z 
(should be the actual value of a correspondent peak), and go so many m/z on either
side (say 3 SD's), and then take **all** of the peaks from all of the scans within that window,
and calculate their squared distance to (the main peak / their own correspondent peak)
and then divide by (the number of peaks total - the number of corresponding peaks).

We may be able to find an interesting normalization factor by taking the most
intense average peak, and the ratio of its correspondent scan peaks to it,
and then the set of peaks that are within 1/2 of the intensity of that peak.


```{r raw_data, eval = FALSE}
raw_data <- RawMS$new("UK001N1exoposb.mzML", "UK001N1exoposb_metadata.json")
save(raw_data, file = "raw_data.RData")
```

```{r load_data}
load("raw_data.RData")
```


```{r digital_resolution}
all_scans <- lapply(seq(raw_data$scan_range), function(in_scan){
  tmp_rawdata <- as.data.frame(xcms::getScan(raw_data$raw_data, in_scan))
  filter_rawdata <- SIRM.FTMS.peakPickingMethods:::get_scan_nozeros(tmp_rawdata)
  filter_rawdata
})

all_scans_merge <- do.call(rbind, all_scans)
all_fit <- exponential_fit(all_scans_merge$mz, all_scans_merge$lag, n_exp = 3)$coefficients
all_fit <- data.frame(coef = all_fit, which = letters[1:4], type = "all")

scan_models <- lapply(seq(raw_data$scan_range), function(in_scan){
  tmp_rawdata <- as.data.frame(xcms::getScan(raw_data$raw_data, in_scan))
  filter_rawdata <- SIRM.FTMS.peakPickingMethods:::get_scan_nozeros(tmp_rawdata)
  tmp <- exponential_fit(filter_rawdata$mz, filter_rawdata$lag, n_exp = 3)$coefficients
  data.frame(coef = tmp, which = letters[1:4], type = "indiv")
})

scan_coeffs <- do.call(rbind, scan_models)

mean_coeffs <- dplyr::group_by(scan_coeffs, which) %>% dplyr::summarise(., coef = mean(coef))

library(ggforce)

ggplot(scan_coeffs, aes(x = which, y = coef)) + geom_sina(bins = 40) +
  geom_point(data = all_fit, color = "blue") +
  geom_point(data = mean_coeffs, color = "red") + 
  facet_wrap(~which, scales = "free")
```

Based on this, the coefficients aren't changing a whole lot.

Lets see what happens when we graph the predictions from both against each other

```{r graph_preds}
mean_pred <- data.frame(x = rep(all_scans[[1]]$mz, 2),
                        y = c(exponential_predict(mean_coeffs$coef, all_scans[[1]]$mz),
                              exponential_predict(all_fit$coef, all_scans[[1]]$mz)),
                        which = rep(c("mean", "all"), each = nrow(all_scans[[1]])))

ggplot(mean_pred, aes(x = x, y = y, color = which)) + geom_point()

tmp_pred <- data.frame(mean = filter(mean_pred, which == "mean") %>% select(., y),
                       all = filter(mean_pred, which == "all") %>% select(., y))
names(tmp_pred) <- c("mean", "all")
ggplot(tmp_pred, aes(x = mean, y = all)) + geom_point()

tmp_pred <- mutate(tmp_pred, diff = abs(mean - all))
tmp_pred$mz <- all_scans[[1]]$mz

ggplot(tmp_pred, aes(x = diff)) + geom_histogram(bins = 40)
```



```{r get_peaks_from_multiple_scans, cache=TRUE, cache.lazy=FALSE}
options(mc.cores = 10)
multi_scan <- MultiScans$new(raw_data)
save(multi_scan, file = "test_multi_scan.RData")
```

Lets test various multipliers of the resolution to see where we get diminishing
returns on widening the resolution.

```{r correspondence, cache = TRUE, cache.lazy=FALSE}
thirds <- MasterPeakList$new(multi_scan, multiplier = 1/3)

seconds <- MasterPeakList$new(multi_scan, multiplier = 1/2)

once <- MasterPeakList$new(multi_scan, multiplier = 1)

twice2 <- MasterPeakList$new(multi_scan, multiplier = 2)

three <- MasterPeakList$new(multi_scan, multiplier = 3)
```

```{r all_novel}
all_novel <- list(thirds = data.frame(name = "thirds",
                                      n_peak = thirds$novel_peaks,
                                      scan = seq(1, length(thirds$novel_peaks))),
                  seconds = data.frame(name = "seconds",
                                      n_peak = seconds$novel_peaks,
                                      scan = seq(1, length(seconds$novel_peaks))),
                  once = data.frame(name = "once",
                                      n_peak = once$novel_peaks,
                                      scan = seq(1, length(once$novel_peaks))),
                  twice = data.frame(name = "twice",
                                      n_peak = twice$novel_peaks,
                                      scan = seq(1, length(twice$novel_peaks))),
                  three = data.frame(name = "three",
                                      n_peak = three$novel_peaks,
                                      scan = seq(1, length(three$novel_peaks))))
all_novel <- do.call(rbind, all_novel)
ggplot(all_novel, aes(x = scan, y = n_peak, color = name)) + geom_line()
```

It looks like from 2x to 3x there is very little difference in the number of novel
peaks as each scan is added. So let's use 3x as the default from here on out.

## Run Correspondence on Different Peak Types

```{r different_correspondenc, cache = TRUE, cache.lazy=FALSE}
peak_types <- c("basic", "area", "rsq_98", "rsq_95", "area_hislope",
                "lm_weighted", "nls_weighted")
options(mc.cores = 10)

use_dir <- paste0("fcs_runs_", make.names(Sys.time()))
dir.create(use_dir)

peak_results <- mclapply(peak_types, function(in_type){
  fcs <- FindCorrespondenceScans$new(multi_scan, peak_calc_type = in_type, multiplier = 3)
  save(fcs, file = file.path(use_dir, paste0("fcs_", in_type, ".RData")))
})

save(peak_results, file = file.path(use_dir, "fcs_all.RData"))
```


## SD Based Correspondence

After implementing the basic peak correspondence algorithm across scans, lets
look at how the modeled standard deviation changes over the iterations.

```{r fcp_models, eval = FALSE}
load("test_fcp.RData")
all_models <- lapply(seq(1, length(fcp$sd_models)), function(x){
  data.frame(mz = fcp$master_peak_list$master,
             sd = exponential_predict(fcp$sd_models[[x]], fcp$master_peak_list$master),
             char_which = as.character(x),
             num_which = x)
})

all_models <- do.call(rbind, all_models)

ggplot(all_models, aes(x = mz, y = sd, color = char_which)) + geom_line()
ggplot(dplyr::filter(all_models, num_which >= 3), aes(x = mz, y = sd, color = char_which)) + geom_line()
```

Just for funsies, lets turn this into a problem of examining the standard
deviation across the iterations.

```{r variances, eval = FALSE}
library(visualizationQualityControl)
library(dplyr)

summarize_which_cols <- function(in_data, min_model = 1){
  wide_data <- dplyr::filter(in_data, num_which >= min_model) %>%
    dplyr::select(., char_which, mz, sd) %>%
    tidyr::spread(., key = char_which, value = sd) 
  
  wide_no_mz <- dplyr::select(wide_data, -mz)
  
  summarized_values <- summarize_data(t(wide_no_mz))
  summarized_values$mz <- rep(wide_data$mz, 3)
  summarized_values
}

ggplot(summarize_which_cols(all_models, 1), aes(x = mz, y = var)) + geom_point() + facet_grid(type ~ ., scales = "free_y")
ggplot(summarize_which_cols(all_models, 3), aes(x = mz, y = var)) + geom_point() + facet_grid(type ~ ., scales = "free_y")
ggplot(summarize_which_cols(all_models, 4), aes(x = mz, y = var)) + geom_point() + facet_grid(type ~ ., scales = "free_y")
ggplot(summarize_which_cols(all_models, 5), aes(x = mz, y = var)) + geom_point() + facet_grid(type ~ ., scales = "free_y")
```


This actually looks really neat, and it helps to define that we've probably finished
somewhere around iteration 4 or 5. So hopefully the code change will show that.

# Things to Do

* Run each of the peak finding methods through the peak correspondence
* Plot the SD's and the model values for all M/Z to show that the model is truly
invariant to the spikes that are likely from HPD sites
* Plot the # of correspondent peaks vs average intensity
* Generate some peak lists for Josh to run SELDON on
* Generate HPD regions using average and basic peak finding, re-run correspondence
with those regions removed
* From raw, extract the intensity / mz data for all of the scans to give to Josh

## RMSD vs MZ, Raw vs Model

We want to show that the model generation is relatively invariant to the spikes
in the RMSD values. To do that, we plot the **raw** RMSD vs MZ, and the model
RMSD vs MZ.

```{r rmsd_mz, eval = FALSE}
load("mz_rmsd.RData")

mz_rmsd$type <- "raw"

mz_model <- exponential_fit(mz_rmsd$mz, mz_rmsd$rmsd, n_exp = 3)
mz_rmsd_2 <- data.frame(mz = mz_rmsd$mz, rmsd = exponential_predict(mz_model$coefficients, mz_rmsd$mz),
                        type = "model")
mz_rmsd <- rbind(mz_rmsd, mz_rmsd_2)

p <- ggplot(dplyr::filter(mz_rmsd, type == "raw"), aes(x = mz, y = rmsd)) + geom_point(alpha = 0.25) +
  geom_line(data = dplyr::filter(mz_rmsd, type == "model"), color = "blue", size = 1.5, alpha = 0.5) +
  ggtitle("RMSD vs MZ")
p
```

## Examine # of Correspondent Peaks vs Average Intensity

We want to see if there is a relationship between the intensity of a peak
and the number of correspondent peaks.

```{r compare_peaks, eval = FALSE}
use_dir <- "fcs_runs_X2017.02.07.12.07.43"
peak_types <- c("basic", "area", "rsq_98", "rsq_95", "area_hislope",
                "lm_weighted", "nls_weighted")
file_names <- paste0("fcs_", peak_types, ".RData")

use_file <- file.path(use_dir, file_names[6])

load(use_file)

master_intensity <- function(in_master){
  intensity_values <- lapply(seq(1, length(in_master$master)), function(in_row){
    data.frame(intensity = mean(in_master$scan_intensity[in_row, ], na.rm = TRUE),
               sd = sd(in_master$scan_intensity[in_row, ], na.rm = TRUE))
  })
  intensity_values <- do.call(rbind, intensity_values)
  intensity_values$rsd <- intensity_values$sd / intensity_values$intensity
  intensity_values
}

lm_intensity <- master_intensity(fcs$master_peak_list)
lm_intensity$n_cor <- fcs$master_peak_list$count_notna()

q <- ggplot(lm_intensity, aes(x = as.factor(n_cor), y = log10(intensity))) + geom_sina(bins = 20)
q
```



# Workflow for Transient-Level Peak Finding

* Transform to log-space
* Find peaks using `pracma::findpeaks`
* For each peak:
    * Check that non-zero points have significant area
    * Fit a parabolic model to non-zero points
    * Find the peak center and intensity based on the model
    * Integrate parabola and sides to get peak area


