---
title: "Transform Raw Data"
author: "Robert M Flight"
date: "`r Sys.time()`"
output:
  pdf_document: default
  html_document: default
---

```{r setup, echo = FALSE, include = FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
```


## Purpose

Hunter has an idea about applying both the normalization and possibly M/Z correction
to the `raw` scan level data, and see if we can do something about **noise**
detection in general. See [this issue](https://gitlab.cesb.uky.edu/rmflight/SIRM.FTMS.peakCharacterization/issues/21)
for some discussion.

To do this, we need to do two things:

1. Verify that we can sum / average scans the same way that `xcms` does after
extracting the raw data peaks

2. Be able to apply the normalization and/or m/z corrections to the `raw` data
points.

## Verify Summations

First, lets see if we can do what we need to with the raw data points. Normally,
we extract each scan by scan, and if we want to do something with the averaged
spectrum, we let `xcms` do it for us. But now we want to do everything ourselves,
so we need to verify we can get the same result.

```{r xcms_summation}
library(SIRM.FTMS.peakCharacterization)
library(xcms)
library(cowplot)
library(dplyr)

zip_data <- zip_ms("test_files/bcal_good_UK001N1exoposb.mzML", load_raw = TRUE, load_peak_list = FALSE)

xcms_sum <- as.data.frame(xcms::getSpec(zip_data$raw_ms$raw_data, scanrange = c(1, 30)))
```


For our own summation, we will borrow from the source code of `xcms` itself.

```{r own_summation}
all_scans <- purrr::map_df(seq(1, 30), function(in_scan){
  tmp_frame <- as.data.frame(xcms::getScan(zip_data$raw_ms$raw_data, scan = in_scan))
  tmp_frame$scan <- in_scan
  tmp_frame
})

all_mz <- sort(unique(all_scans$mz))

int_matrix <- matrix(NA, nrow = length(all_mz), ncol = length(unique(all_scans$scan)))

for (iscan in unique(all_scans$scan)) {
  sub_data <- all_scans[all_scans$scan %in% iscan, ]
  match_mz <- all_mz %in% sub_data$mz
  int_matrix[match_mz, iscan] <- sub_data$intensity
}

all_int <- rowMeans(int_matrix)

own_sum <- data.frame(mz = all_mz, intensity = all_int)
```

```{r compare_sums}
xcms_sum[is.na(xcms_sum$intensity), "intensity"] <- 0

all.equal(xcms_sum, own_sum)
all.equal(xcms_sum$mz, own_sum$mz)

use_points <- sample(seq(1, nrow(own_sum)), 10000)
plot(xcms_sum$intensity[use_points], own_sum$intensity[use_points])
```

OK, not quite what I expected. Looking at the source code of the `getSpec` method,
there is a call to `approx`, which looks like it does some linear interpolation.
The question is: **is that the correct thing to do?**. Only one way to find out.

## Check Whether Linear Interpolation is Good Idea

To verify if using `approx` makes sense, lets do peak detection on the `xcms_sum`,
and then compare the point intensities to see if `xcms` or our method makes more
sense.

```{r find_peaks_compare}
found_peaks <- pracma::findpeaks(xcms_sum$intensity, nups = 4)
peak_index <- seq(found_peaks[1, 3], found_peaks[1, 4])

test_peak <- xcms_sum[peak_index, ]
test_peak$type <- "xcms"
own_sum$type <- "own"
test_peak <- rbind(test_peak, own_sum[peak_index, ])

ggplot(test_peak, aes(x = mz, y = intensity, color = type)) + geom_point() + geom_line()
```

OK, so based on this plot, it **definitely makes sense** to use `approx` and do
some form of linear interpolation.

But lets also evaluate what are the individual peaks from each scan underneath this thing.

```{r indiv_peaks}
mz_range <- range(test_peak$mz)

test_scans <- filter(all_scans, (mz >= mz_range[1]) & (mz <= mz_range[2]))

ggplot(test_scans, aes(x = mz, y = intensity, color = as.factor(scan))) + geom_point() + geom_line()
```

Now lets look at what `approx` does using our little test peak.

```{r use_approx}
test_mz <- all_mz[(all_mz >= mz_range[1]) & (all_mz <= mz_range[2])]

int_df <- purrr::map_df(unique(test_scans$scan), function(in_scan){
  scan_df <- filter(test_scans, scan %in% in_scan)
  out_int <- approx(x = scan_df$mz, y = scan_df$intensity, xout = test_mz)$y
  data.frame(mz = test_mz, intensity = out_int, scan = in_scan)
})

ggplot(int_df, aes(x = mz, y = intensity, color = as.factor(scan))) + geom_point() + geom_line()
```

So, we definitely need to use `approx` to interpolate the values. This is useful 
to know. We at least need to do this when we try to average the points together.

```{r averave_approx}
int_matrix2 <- matrix(0, nrow = length(test_mz), ncol = length(unique(test_scans$scan)))
colnames(int_matrix2) <- unique(test_scans$scan)

for (iscan in unique(test_scans$scan)) {
  scan_df <- filter(test_scans, scan %in% iscan)
  int_matrix2[, as.character(iscan)] <- approx(x = scan_df$mz, y = scan_df$intensity, xout = test_mz)$y
}
int_matrix2[is.na(int_matrix2)] <- 0

own_sum2 <- data.frame(mz = test_mz, intensity = rowMeans(int_matrix2, na.rm = TRUE))

xcms_sum2 <- as.data.frame(xcms::getSpec(zip_data$raw_ms$raw_data, scanrange = unique(test_scans$scan)))
xcms_sum2 <- filter(xcms_sum2, (mz >= mz_range[1]) & (mz <= mz_range[2]))
xcms_sum2$type <- "xcms"
own_sum2$type <- "own"
test_avg <- rbind(own_sum2, xcms_sum2)

ggplot(test_avg, aes(x = mz, y = intensity, color = type)) + geom_line() + geom_point()
```

Hmmm, still have an issue with difference in intensities, lets try doing it for
the 30 scans and see what happens instead.

```{r own_sum_approx}
int_matrix3 <- matrix(nrow = length(all_mz), ncol = length(unique(all_scans$scan)))

for (iscan in unique(all_scans$scan)) {
  sub_data <- all_scans[all_scans$scan %in% iscan, ]
  int_matrix3[, iscan] <- approx(x = sub_data$mz, y = sub_data$intensity, xout = all_mz)$y
}

all_int3 <- rowMeans(int_matrix3)

own_sum3 <- data.frame(mz = all_mz, intensity = all_int3)

xcms_sum2 <- as.data.frame(xcms::getSpec(zip_data$raw_ms$raw_data, scanrange = c(1, 30)))

all.equal(own_sum3, xcms_sum2)
```

WooHoo! Got the exact same results, working from the extracted scans. And it
sort of makes sense, in that we add data points to each scan that are interpolated
from the full set of points. So, based on this, we should be able to normalize
the scan to scan intensities rather easily and then do a new average.

Lets look at our little test peak again between the two cases.

```{r}
own_sum3$type <- "own"
xcms_sum2$type <- "xcms"

test_2 <- rbind(own_sum3, xcms_sum2)
test_2 <- filter(test_2, (mz >= mz_range[1]) & (mz <= mz_range[2]))

ggplot(test_2, aes(x = mz, y = intensity, color = type)) + geom_point() + geom_line()
```

## New Functions

So now we need a new function that can actually do the normalization on the raw
data, and a function that sums the scans properly.

### Sum Scans

So lets take the code we created above, and actually make a function that we
can use out of it.

```{r average_scans}
extract_scans_list <- function(raw_data, mz_range = NULL, scan_range = NULL){
  # this code is a re-implementation of the getSpec method in xcms. This is because
  # there is no way to get the scans and the unique_mz from xcms w/out averaging
  # them at the end.
  selection <- xcms::profRange(raw_data, mzrange = mz_range, scanrange = scan_range)
  scan_indices <- selection$scanidx
  scans <- list(length(scan_indices))
  unique_mz <- numeric()
  for (iscan in seq(along = scan_indices)) {
    scans[[iscan]] <- xcms::getScan(raw_data, scan_indices[iscan], selection$mzrange)
    unique_mz <- unique(c(unique_mz, scans[[iscan]][, "mz"]))
  }
  
  unique_mz <- sort(unique_mz)
  
  list(mz = unique_mz, scans = scans)
}

sum_scans_list <- function(scans_list){
  
  scans <- scans_list$scans
  unique_mz <- scans_list$mz
  scan_indices <- seq_along(scans)
  
  intensity_matrix <- matrix(nrow = length(unique_mz), ncol = length(scan_indices))
  
  for (iscan in scan_indices) {
    intensity_matrix[, iscan] <- approx(x = scans[[iscan]][, "mz"], y = scans[[iscan]][, "intensity"],
                                        xout = unique_mz)$y
  }
  
  data.frame(mz = unique_mz, intensity = rowSums(intensity_matrix, na.rm = TRUE))
  
}
```

### Normalize Scans

Ideally, in our case, we also want to be able to normalize the scans before
we average them.

```{r normalize_scans}
normalize_scans_list <- function(scans_list, normalization_factors, scan_indices){
  scans <- scans_list$scans
  
  scans <- scans[scan_indices]
  
  normalized_scans <- purrr::map(seq_along(scan_indices), function(in_index){
    tmp_scan <- scans[[in_index]]
    
    tmp_scan[, "intensity"] <- exp(log(tmp_scan[, "intensity"]) - normalization_factors[in_index])
    
    tmp_scan
    
  })
  
  scans_list$scans <- normalized_scans
  scans_list
}
```

## Comparisons

Now that we have all of our functions defined, lets compare what happens when
we average raw and normalized data.

```{r load_processed_data}
zip_processed <- zip_ms("test_files/zip_rawtransformationX2017.12.01.13.00.38/bcal_good_UK001N1exoposb.zip")
raw_data <- zip_processed$raw_ms$raw_data
scan_range <- range(zip_processed$raw_ms$scan_range)

zip_processed$load_peak_finder()
normalization_factors <- zip_processed$peak_finder$correspondent_peaks$master_peak_list$normalization_factors
scan_indices <- zip_processed$peak_finder$correspondent_peaks$master_peak_list$scan_indices
```

```{r raw_data_averaging}
raw_scans <- extract_scans_list(raw_data, scan_range = scan_range)

# need to make the set of scans that get averaged the same
raw_scans$scans <- raw_scans$scans[scan_indices]

raw_sum <- sum_scans_list(raw_scans)
```

```{r average_normalized_data}
norm_scans <- extract_scans_list(raw_data, scan_range = scan_range)

norm_scans <- normalize_scans_list(norm_scans, normalization_factors, scan_indices)

norm_sum <- sum_scans_list(norm_scans)
```

## Compare Peaks & Distributions

```{r raw_peaks}
raw_sum <- filter(raw_sum, !is.na(intensity))
raw_peaks <- SIRM.FTMS.peakCharacterization:::generate_peaks(raw_sum, n_peak = Inf)
```

```{r norm_peaks}
norm_sum <- filter(norm_sum, !is.na(intensity))
norm_peaks <- SIRM.FTMS.peakCharacterization:::generate_peaks(norm_sum, n_peak = Inf)
```


```{r plot_them, fig.width=8, fig.height = 6}
raw_peaks$type <- "raw"
norm_peaks$type <- "normalized"

all_data <- rbind(raw_peaks, norm_peaks)
all_data$type <- forcats::fct_relevel(all_data$type, "raw", "normalized")

ggplot(all_data, aes(x = log10(Height))) + geom_histogram(bins = 200, position = "identity") + facet_wrap(~ type, nrow = 2, ncol = 1) + xlim(c(1, 7))
```

## Peaks That Might Not Be Noise

So, now, based on our conversations, assuming that **noise** is **not additive**,
we should be able to define an upper cutoff on the normalized data based on
the highest noise cutoff of our scans after applying the normalization. 

This cutoff can be applied to the **summed** data, and then we can look for peaks
that are underneath the peaks in the **summed** data and see if they were previously
noise.

### Normalize Noise and Get Max Threshold

So we need to grab the noise data, normalize the threshold, and return the maximum.

```{r normalize_noise_max_threshold}
normalize_noise_max <- function(mspl, normalization_factors, scan_indices = NULL) {
  if (is.null(scan_indices)) {
    scan_indices <- seq(1, length(normalization_factors))
  }
  
  mspl$scan_indices <- scan_indices
  
  noise_thresholds <- mspl$get_noise_info()$threshold
  
  norm_thresholds <- exp(log(noise_thresholds) - normalization_factors)
  
  max(norm_thresholds)
  
}
```

### Normalize Peak Lists

We also need to normalize the peak lists.

```{r normalize_peak_lists}
normalize_peak_lists <- function(mspl, normalization_factors, scan_indices = NULL) {
  if (is.null(scan_indices)) {
    scan_indices <- seq(1, length(normalization_factors))
  }
  
  mspl$scan_indices <- scan_indices
  
  peak_lists <- purrr::map(mspl$get_scan_peak_lists(), "peak_list")
  
  norm_lists <- purrr::map2(peak_lists, normalization_factors, function(peaks, norm_factor){
    peaks$Height <- exp(log(peaks$Height) - norm_factor)
    peaks
  })
  norm_lists
}
```

### Find Scan Peaks Underneath Summed Peaks

For a set of summed peaks, this function will take the scan peaks and check
if they are **part** of the summed peaks or not. If the summed peaks are above
the noise cutoff, then this should find things that **might have previously**
been noted as noise.

```{r find_scans_under_sums}
scan_peaks_under_sum <- function(sum_peaks, scan_peaks){
  sum_ranges <- purrr::map_df(seq(1, nrow(sum_peaks)), function(in_peak){
    range_peaks <- range(sum_peaks[[in_peak, "points"]][,1])
    data.frame(start = range_peaks[1], stop = range_peaks[2])
  })
  
  convert_factor <- 10000
  
  sum_ranges <- as.matrix(sum_ranges)
  
  sum_ranges <- metabolomicsUtilities::mz_to_iranges(sum_ranges, convert_factor)
  
  if (!inherits(scan_peaks, "data.frame")) {
    scan_peaks <- purrr::map(scan_peaks, function(in_peaks) {
      peak_ranges <- metabolomicsUtilities::mz_to_iranges(in_peaks$ObservedMZ, convert_factor)
      
      overlaps <- IRanges::findOverlaps(sum_ranges, peak_ranges)
      
      in_peaks$sum_peak <- NA
      in_peaks[S4Vectors::subjectHits(overlaps), "sum_peak"] <- sum_peaks[S4Vectors::queryHits(overlaps), "peak"]
      in_peaks$is_under_sum <- peak_ranges %within% sum_ranges
      in_peaks
    })
  } else {
    peak_ranges <- metabolomicsUtilities::mz_to_iranges(scan_peaks$ObservedMZ, convert_factor)
    
    overlaps <- IRanges::findOverlaps(sum_ranges, peak_ranges)
      
    scan_peaks$sum_peak <- NA
    scan_peaks[S4Vectors::subjectHits(overlaps), "sum_peak"] <- sum_peaks[S4Vectors::queryHits(overlaps), "peak"]
    
    scan_peaks$is_under_sum <- peak_ranges %within% sum_ranges
  }
  scan_peaks
}
```

## Actually Run It

```{r peaks_under_sums}
mspl <- zip_processed$peak_finder$multi_scan_peaklist$clone(deep = TRUE)
max_noise <- normalize_noise_max(mspl, normalization_factors, scan_indices)

sum_not_noise <- filter(norm_peaks, Height > (max_noise * 1.5))
normed_peak_lists <- normalize_peak_lists(mspl, normalization_factors, scan_indices)

noise_rechecked <- scan_peaks_under_sum(sum_not_noise, normed_peak_lists)
```

## How Many Are Affected?

```{r how_many_affected}
noise_info <- mspl$get_noise_info()
n_affected <- purrr::map_df(seq(1, length(noise_rechecked)), function(which_check){
  tmp_peaks <- noise_rechecked[[which_check]]
  data.frame(scan = noise_info$scan[which_check],
             new_peaks = sum(!tmp_peaks$not_noise & tmp_peaks$is_under_sum))
})
```

```{r show_table, results='asis'}
n_affected

dplyr::left_join(noise_info, n_affected)
```

